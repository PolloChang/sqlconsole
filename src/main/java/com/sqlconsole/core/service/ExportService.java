package com.sqlconsole.core.service;

import com.sqlconsole.core.model.dto.ExportJobStatus;
import com.sqlconsole.core.model.dto.ExportJobStatus.Status;
import java.io.File;
import java.io.FileOutputStream;
import java.sql.ResultSetMetaData;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.poi.ss.usermodel.Cell;
import org.apache.poi.ss.usermodel.Row;
import org.apache.poi.ss.usermodel.Sheet;
import org.apache.poi.xssf.streaming.SXSSFWorkbook;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Lazy;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

@Service
@Slf4j
@RequiredArgsConstructor
public class ExportService {

  private final SqlExecutorService sqlExecutorService;
  private final Map<String, ExportJobStatus> jobStore = new ConcurrentHashMap<>();

  @Autowired @Lazy private ExportService self;

  public String submitJob(Long dbId, String sql, String username) {
    String jobId = UUID.randomUUID().toString();
    ExportJobStatus job =
        ExportJobStatus.builder()
            .jobId(jobId)
            .status(Status.PENDING)
            .percentage(0)
            .build();
    jobStore.put(jobId, job);

    // Call async method via self-proxy to ensure @Async works
    self.executeBackgroundExport(jobId, dbId, sql, username);

    return jobId;
  }

  @Async("exportTaskExecutor")
  public void executeBackgroundExport(String jobId, Long dbId, String sql, String username) {
    ExportJobStatus job = jobStore.get(jobId);
    if (job == null) return;

    job.setStatus(Status.PROCESSING);

    SXSSFWorkbook workbook = new SXSSFWorkbook(100); // Keep 100 rows in memory
    File tempFile = null;

    try {
      Sheet sheet = workbook.createSheet("Export Data");

      // Pass user role as ROLE_USER to enforce permission checks
      sqlExecutorService.streamQuery(
          dbId,
          sql,
          username,
          "ROLE_USER",
          rs -> {
            try {
              ResultSetMetaData meta = rs.getMetaData();
              int colCount = meta.getColumnCount();

              // Header
              Row headerRow = sheet.createRow(0);
              for (int i = 1; i <= colCount; i++) {
                Cell cell = headerRow.createCell(i - 1);
                cell.setCellValue(meta.getColumnLabel(i));
              }

              int rowIndex = 1;
              while (rs.next()) {
                Row row = sheet.createRow(rowIndex++);
                for (int i = 1; i <= colCount; i++) {
                  Cell cell = row.createCell(i - 1);
                  Object val = rs.getObject(i);
                  if (val != null) {
                    cell.setCellValue(val.toString());
                  }
                }
              }
            } catch (Exception e) {
              throw new RuntimeException(e);
            }
          });

      // Write to temp file
      tempFile = File.createTempFile("export_" + jobId, ".xlsx");
      try (FileOutputStream out = new FileOutputStream(tempFile)) {
        workbook.write(out);
      }

      job.setFilePath(tempFile.getAbsolutePath());
      job.setStatus(Status.COMPLETED);
      job.setPercentage(100);

    } catch (Exception e) {
      log.error("Export failed for job {}", jobId, e);
      job.setStatus(Status.FAILED);
      job.setErrorMessage(e.getMessage());
      if (tempFile != null && tempFile.exists()) {
        tempFile.delete();
      }
    } finally {
      // Dispose of temporary files generated by SXSSF
      workbook.dispose();
      try {
        workbook.close();
      } catch (Exception e) {
        log.warn("Failed to close workbook", e);
      }
    }
  }

  public ExportJobStatus getStatus(String jobId) {
    return jobStore.get(jobId);
  }
}
